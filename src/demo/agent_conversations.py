"""
DM4: Agentå¯¹è¯å¢å¼º (Agent Demo Conversations)

èŒè´£:
- æä¾›é¢„è®¾ç²¾å½©å¯¹è¯åœºæ™¯
- å±•ç¤ºAgentæ¨ç†è¿‡ç¨‹
- æ¨¡æ‹Ÿå­¦ä¹ åé¦ˆ
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
import random

logger = logging.getLogger(__name__)


class ConversationScenario(str, Enum):
    """é¢„è®¾å¯¹è¯åœºæ™¯"""
    TASK_SCHEDULING = "task_scheduling"      # ä»»åŠ¡è°ƒåº¦
    STATUS_QUERY = "status_query"            # çŠ¶æ€æŸ¥è¯¢
    PROBLEM_DIAGNOSIS = "problem_diagnosis"  # é—®é¢˜è¯Šæ–­
    DATA_ANALYSIS = "data_analysis"          # æ•°æ®åˆ†æ
    BATCH_OPERATION = "batch_operation"      # æ‰¹é‡æ“ä½œ


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step: int
    action: str
    description: str
    result: Optional[str] = None
    duration_ms: int = 0


@dataclass
class AgentResponse:
    """Agentå“åº”"""
    message: str
    reasoning_steps: List[ReasoningStep]
    suggestions: List[str] = field(default_factory=list)
    actions: List[Dict[str, Any]] = field(default_factory=list)
    requires_confirmation: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "message": self.message,
            "reasoning_steps": [
                {
                    "step": s.step,
                    "action": s.action,
                    "description": s.description,
                    "result": s.result,
                    "duration_ms": s.duration_ms
                }
                for s in self.reasoning_steps
            ],
            "suggestions": self.suggestions,
            "actions": self.actions,
            "requires_confirmation": self.requires_confirmation,
            "metadata": self.metadata
        }


@dataclass
class ConversationMessage:
    """å¯¹è¯æ¶ˆæ¯"""
    role: str  # user, agent, system
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    reasoning: Optional[AgentResponse] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "role": self.role,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
            "reasoning": self.reasoning.to_dict() if self.reasoning else None
        }


class AgentConversationService:
    """
    Agentå¯¹è¯æ¼”ç¤ºæœåŠ¡

    æä¾›é¢„è®¾å¯¹è¯åœºæ™¯å’Œæ™ºèƒ½å“åº”æ¨¡æ‹Ÿ
    """

    _instance: Optional["AgentConversationService"] = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self._initialized = True
        self._conversations: Dict[str, List[ConversationMessage]] = {}
        self._learning_records: List[Dict[str, Any]] = []

        # é¢„è®¾åœºæ™¯é…ç½®
        self._scenario_configs = self._init_scenario_configs()

        logger.info("AgentConversationService initialized")

    def _init_scenario_configs(self) -> Dict[ConversationScenario, Dict[str, Any]]:
        """åˆå§‹åŒ–åœºæ™¯é…ç½®"""
        return {
            ConversationScenario.TASK_SCHEDULING: {
                "name": "ä»»åŠ¡è°ƒåº¦",
                "sample_inputs": [
                    "å®‰æ’æ˜å¤©æ—©ä¸Š8ç‚¹å¤§å ‚æ·±åº¦æ¸…æ´",
                    "å¸®æˆ‘å®‰æ’ä¸€ä¸ªç´§æ€¥æ¸…æ´ä»»åŠ¡",
                    "æ˜å¤©ä¸‹åˆ3ç‚¹å®‰æ’ä¼šè®®å®¤æ¸…æ´"
                ],
                "description": "å±•ç¤ºAgentå¦‚ä½•ç†è§£ä»»åŠ¡éœ€æ±‚å¹¶æ™ºèƒ½å®‰æ’"
            },
            ConversationScenario.STATUS_QUERY: {
                "name": "çŠ¶æ€æŸ¥è¯¢",
                "sample_inputs": [
                    "ç°åœ¨æœ‰å“ªäº›æœºå™¨äººç©ºé—²",
                    "å‘Šè¯‰æˆ‘æœºå™¨äººA-01çš„çŠ¶æ€",
                    "ä»Šå¤©å®Œæˆäº†å¤šå°‘æ¸…æ´ä»»åŠ¡"
                ],
                "description": "å±•ç¤ºAgentå¦‚ä½•æŸ¥è¯¢å’Œæ±‡æ€»ä¿¡æ¯"
            },
            ConversationScenario.PROBLEM_DIAGNOSIS: {
                "name": "é—®é¢˜è¯Šæ–­",
                "sample_inputs": [
                    "28æ¥¼çš„æœºå™¨äººæ€ä¹ˆåœäº†",
                    "ä¸ºä»€ä¹ˆæœºå™¨äººA-03ä¸€ç›´åœ¨å……ç”µ",
                    "æœ‰ä¸ªæœºå™¨äººå¥½åƒå¡ä½äº†"
                ],
                "description": "å±•ç¤ºAgentå¦‚ä½•è¯Šæ–­é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ"
            },
            ConversationScenario.DATA_ANALYSIS: {
                "name": "æ•°æ®åˆ†æ",
                "sample_inputs": [
                    "è¿™å‘¨çš„æ¸…æ´æ•ˆç‡æ€ä¹ˆæ ·",
                    "å¸®æˆ‘åˆ†æä¸€ä¸‹æœ¬æœˆçš„æœºå™¨äººåˆ©ç”¨ç‡",
                    "å“ªä¸ªåŒºåŸŸæ¸…æ´é¢‘ç‡æœ€é«˜"
                ],
                "description": "å±•ç¤ºAgentçš„æ•°æ®åˆ†æèƒ½åŠ›"
            },
            ConversationScenario.BATCH_OPERATION: {
                "name": "æ‰¹é‡æ“ä½œ",
                "sample_inputs": [
                    "æŠŠæ‰€æœ‰ç”µé‡ä½äº30%çš„æœºå™¨äººå¬å›å……ç”µ",
                    "æš‚åœæ‰€æœ‰3æ¥¼çš„æ¸…æ´ä»»åŠ¡",
                    "ç»™æ‰€æœ‰ç©ºé—²æœºå™¨äººåˆ†é…ä»»åŠ¡"
                ],
                "description": "å±•ç¤ºAgentå¤„ç†å¤æ‚æ‰¹é‡æŒ‡ä»¤çš„èƒ½åŠ›"
            }
        }

    # ==================== å¯¹è¯å¤„ç† ====================

    async def process_message(
        self,
        session_id: str,
        user_message: str,
        scenario: Optional[ConversationScenario] = None
    ) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            user_message: ç”¨æˆ·è¾“å…¥
            scenario: æŒ‡å®šåœºæ™¯ (å¯é€‰ï¼Œç”¨äºæ¼”ç¤º)

        Returns:
            Agentå“åº”
        """
        # åˆå§‹åŒ–ä¼šè¯
        if session_id not in self._conversations:
            self._conversations[session_id] = []

        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        self._conversations[session_id].append(
            ConversationMessage(role="user", content=user_message)
        )

        # æ£€æµ‹åœºæ™¯
        if scenario is None:
            scenario = self._detect_scenario(user_message)

        # ç”Ÿæˆå“åº”
        response = await self._generate_response(user_message, scenario)

        # è®°å½•Agentå“åº”
        self._conversations[session_id].append(
            ConversationMessage(role="agent", content=response.message, reasoning=response)
        )

        return response

    def _detect_scenario(self, message: str) -> ConversationScenario:
        """æ£€æµ‹ç”¨æˆ·æ„å›¾å¯¹åº”çš„åœºæ™¯"""
        message_lower = message.lower()

        # ä»»åŠ¡è°ƒåº¦å…³é”®è¯
        if any(kw in message_lower for kw in ["å®‰æ’", "è°ƒåº¦", "æ´¾å‘", "æ¸…æ´ä»»åŠ¡", "æ·±åº¦æ¸…æ´"]):
            return ConversationScenario.TASK_SCHEDULING

        # çŠ¶æ€æŸ¥è¯¢å…³é”®è¯
        if any(kw in message_lower for kw in ["çŠ¶æ€", "ç©ºé—²", "åœ¨å“ª", "ä½ç½®", "ç”µé‡", "å®Œæˆäº†å¤šå°‘"]):
            return ConversationScenario.STATUS_QUERY

        # é—®é¢˜è¯Šæ–­å…³é”®è¯
        if any(kw in message_lower for kw in ["æ€ä¹ˆäº†", "åœäº†", "æ•…éšœ", "å¡ä½", "é—®é¢˜", "ä¸ºä»€ä¹ˆ"]):
            return ConversationScenario.PROBLEM_DIAGNOSIS

        # æ•°æ®åˆ†æå…³é”®è¯
        if any(kw in message_lower for kw in ["åˆ†æ", "æ•ˆç‡", "ç»Ÿè®¡", "åˆ©ç”¨ç‡", "æŠ¥è¡¨", "è¿™å‘¨", "æœ¬æœˆ"]):
            return ConversationScenario.DATA_ANALYSIS

        # æ‰¹é‡æ“ä½œå…³é”®è¯
        if any(kw in message_lower for kw in ["æ‰€æœ‰", "æ‰¹é‡", "å…¨éƒ¨", "ä½äº", "å¬å›"]):
            return ConversationScenario.BATCH_OPERATION

        # é»˜è®¤ä¸ºçŠ¶æ€æŸ¥è¯¢
        return ConversationScenario.STATUS_QUERY

    async def _generate_response(
        self,
        user_message: str,
        scenario: ConversationScenario
    ) -> AgentResponse:
        """ç”ŸæˆAgentå“åº”"""

        if scenario == ConversationScenario.TASK_SCHEDULING:
            return await self._handle_task_scheduling(user_message)
        elif scenario == ConversationScenario.STATUS_QUERY:
            return await self._handle_status_query(user_message)
        elif scenario == ConversationScenario.PROBLEM_DIAGNOSIS:
            return await self._handle_problem_diagnosis(user_message)
        elif scenario == ConversationScenario.DATA_ANALYSIS:
            return await self._handle_data_analysis(user_message)
        elif scenario == ConversationScenario.BATCH_OPERATION:
            return await self._handle_batch_operation(user_message)
        else:
            return self._generate_fallback_response()

    # ==================== åœºæ™¯å¤„ç†å™¨ ====================

    async def _handle_task_scheduling(self, message: str) -> AgentResponse:
        """å¤„ç†ä»»åŠ¡è°ƒåº¦åœºæ™¯"""

        # æ¨¡æ‹Ÿæ¨ç†å»¶è¿Ÿ
        await asyncio.sleep(0.3)

        # è§£ææ—¶é—´
        scheduled_time = "æ˜å¤© 08:00"
        if "ä¸‹åˆ" in message:
            scheduled_time = "æ˜å¤© 15:00"
        elif "æ™šä¸Š" in message:
            scheduled_time = "æ˜å¤© 20:00"

        # è§£æåŒºåŸŸ
        zone = "å¤§å ‚"
        if "ä¼šè®®å®¤" in message:
            zone = "ä¼šè®®å®¤"
        elif "èµ°å»Š" in message:
            zone = "èµ°å»Š"
        elif "æ´—æ‰‹é—´" in message:
            zone = "æ´—æ‰‹é—´"

        # è§£æä»»åŠ¡ç±»å‹
        task_type = "routine"
        if "æ·±åº¦" in message:
            task_type = "deep_clean"
        elif "ç´§æ€¥" in message:
            task_type = "emergency"

        reasoning_steps = [
            ReasoningStep(
                step=1,
                action="parse_intent",
                description="è§£æç”¨æˆ·æ„å›¾",
                result=f"åˆ›å»ºæ¸…æ´ä»»åŠ¡ - {task_type}",
                duration_ms=45
            ),
            ReasoningStep(
                step=2,
                action="identify_zone",
                description="è¯†åˆ«ç›®æ ‡åŒºåŸŸ",
                result=f"åŒºåŸŸ: {zone} (zone_lobby_001)",
                duration_ms=32
            ),
            ReasoningStep(
                step=3,
                action="parse_time",
                description="è§£ææ—¶é—´å®‰æ’",
                result=f"æ—¶é—´: {scheduled_time}",
                duration_ms=28
            ),
            ReasoningStep(
                step=4,
                action="evaluate_resources",
                description="è¯„ä¼°å¯ç”¨èµ„æº",
                result="éœ€è¦2å°æœºå™¨äººï¼Œé¢„è®¡90åˆ†é’Ÿ",
                duration_ms=156
            ),
            ReasoningStep(
                step=5,
                action="select_robots",
                description="é€‰æ‹©æœ€ä¼˜æœºå™¨äºº",
                result="æ¨è: æ¸…æ´æœºå™¨äºº A-01, A-02",
                duration_ms=89
            ),
            ReasoningStep(
                step=6,
                action="generate_plan",
                description="ç”Ÿæˆæ‰§è¡Œè®¡åˆ’",
                result="å·²ç”Ÿæˆä»»åŠ¡è®¡åˆ’ï¼Œç­‰å¾…ç¡®è®¤",
                duration_ms=67
            )
        ]

        return AgentResponse(
            message=f"""å¥½çš„ï¼Œæˆ‘å·²ä¸ºæ‚¨å®‰æ’{scheduled_time}çš„{zone}{'æ·±åº¦' if task_type == 'deep_clean' else ''}æ¸…æ´ä»»åŠ¡ã€‚

**ä»»åŠ¡è¯¦æƒ…:**
- ç›®æ ‡åŒºåŸŸ: {zone}
- è®¡åˆ’æ—¶é—´: {scheduled_time}
- ä»»åŠ¡ç±»å‹: {'æ·±åº¦æ¸…æ´' if task_type == 'deep_clean' else 'å¸¸è§„æ¸…æ´'}
- é¢„è®¡ç”¨æ—¶: 90åˆ†é’Ÿ
- æ¸…æ´é¢ç§¯: çº¦800ã¡

**èµ„æºåˆ†é…:**
- æœºå™¨äºº: æ¸…æ´æœºå™¨äºº A-01ã€A-02
- A-01 å½“å‰ç”µé‡: 85%ï¼Œè·ç¦»ç›®æ ‡åŒºåŸŸçº¦3åˆ†é’Ÿ
- A-02 å½“å‰ç”µé‡: 92%ï¼Œå¯ä½œä¸ºå¤‡é€‰

æ˜¯å¦ç¡®è®¤æ‰§è¡Œæ­¤ä»»åŠ¡ï¼Ÿ""",
            reasoning_steps=reasoning_steps,
            suggestions=[
                "å¯ä»¥è°ƒæ•´æ‰§è¡Œæ—¶é—´",
                "å¯ä»¥é€‰æ‹©å…¶ä»–æœºå™¨äºº",
                "å¯ä»¥ä¿®æ”¹æ¸…æ´ç±»å‹"
            ],
            actions=[
                {"type": "create_task", "zone": zone, "time": scheduled_time, "robots": ["robot_001", "robot_002"]},
            ],
            requires_confirmation=True,
            metadata={
                "scenario": "task_scheduling",
                "zone": zone,
                "scheduled_time": scheduled_time,
                "task_type": task_type,
                "estimated_duration": 90
            }
        )

    async def _handle_status_query(self, message: str) -> AgentResponse:
        """å¤„ç†çŠ¶æ€æŸ¥è¯¢åœºæ™¯"""

        await asyncio.sleep(0.2)

        reasoning_steps = [
            ReasoningStep(
                step=1,
                action="parse_query",
                description="è§£ææŸ¥è¯¢ç±»å‹",
                result="æŸ¥è¯¢æœºå™¨äººçŠ¶æ€",
                duration_ms=35
            ),
            ReasoningStep(
                step=2,
                action="fetch_data",
                description="è·å–å®æ—¶æ•°æ®",
                result="å·²è·å–8å°æœºå™¨äººçŠ¶æ€",
                duration_ms=78
            ),
            ReasoningStep(
                step=3,
                action="analyze",
                description="åˆ†ææ•°æ®",
                result="ç©ºé—²: 2å°, å·¥ä½œä¸­: 4å°, å……ç”µ: 1å°, ç»´æŠ¤: 1å°",
                duration_ms=45
            ),
            ReasoningStep(
                step=4,
                action="format_response",
                description="ç”Ÿæˆå“åº”",
                result="å·²æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœ",
                duration_ms=23
            )
        ]

        # æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆä¸åŒå“åº”
        if "ç©ºé—²" in message:
            response_msg = """å½“å‰æœ‰ **2å°æœºå™¨äººç©ºé—²**ï¼Œå¯ä»¥ç«‹å³åˆ†é…ä»»åŠ¡:

| æœºå™¨äºº | ä½ç½® | ç”µé‡ | ä»Šæ—¥å®Œæˆ |
|--------|------|------|----------|
| A-02 | ç¯çƒè´¸æ˜“å¹¿åœº 1F | 92% | 5ä¸ªä»»åŠ¡ |
| B-03 | å›½é™…é‡‘èä¸­å¿ƒ 6F | 88% | 4ä¸ªä»»åŠ¡ |

**æ¨è:** A-02 ç”µé‡å……è¶³ä¸”ä»Šæ—¥å·¥ä½œé‡è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆåˆ†é…ã€‚

éœ€è¦æˆ‘ä¸ºç©ºé—²æœºå™¨äººåˆ†é…ä»»åŠ¡å—ï¼Ÿ"""
        elif "å®Œæˆ" in message or "å¤šå°‘" in message:
            response_msg = """**ä»Šæ—¥æ¸…æ´ä»»åŠ¡ç»Ÿè®¡:**

- å·²å®Œæˆ: **127ä¸ªä»»åŠ¡**
- æ¸…æ´é¢ç§¯: **45,800ã¡**
- æ€»å·¥ä½œæ—¶é•¿: **186å°æ—¶**

**å„æ¥¼å®‡å®Œæˆæƒ…å†µ:**
| æ¥¼å®‡ | å®Œæˆä»»åŠ¡ | å®Œæˆç‡ |
|------|----------|--------|
| ç¯çƒè´¸æ˜“å¹¿åœº | 48ä¸ª | 97.2% |
| å›½é™…é‡‘èä¸­å¿ƒ | 42ä¸ª | 96.5% |
| å¤ªå¤å¹¿åœº | 37ä¸ª | 96.2% |

ç›¸æ¯”æ˜¨å¤©ï¼Œä»»åŠ¡å®Œæˆæ•°å¢åŠ äº†8%ã€‚"""
        else:
            response_msg = """**æœºå™¨äººè½¦é˜ŸçŠ¶æ€æ¦‚è§ˆ:**

| çŠ¶æ€ | æ•°é‡ | æœºå™¨äºº |
|------|------|--------|
| ğŸŸ¢ å·¥ä½œä¸­ | 4å° | A-01, B-01, B-02, C-01 |
| ğŸ”µ ç©ºé—² | 2å° | A-02, B-03 |
| ğŸŸ¡ å……ç”µä¸­ | 1å° | A-03 (ç”µé‡35%) |
| ğŸ”§ ç»´æŠ¤ä¸­ | 1å° | C-02 (å®šæœŸä¿å…») |

**å…³é”®æŒ‡æ ‡:**
- æ•´ä½“åˆ©ç”¨ç‡: 87.2%
- å¹³å‡ç”µé‡: 72%
- ä»Šæ—¥å®Œæˆä»»åŠ¡: 127ä¸ª

æœ‰ä»€ä¹ˆéœ€è¦æˆ‘å¸®æ‚¨å¤„ç†çš„å—ï¼Ÿ"""

        return AgentResponse(
            message=response_msg,
            reasoning_steps=reasoning_steps,
            suggestions=[
                "æŸ¥çœ‹è¯¦ç»†æœºå™¨äººä¿¡æ¯",
                "åˆ†é…ä»»åŠ¡ç»™ç©ºé—²æœºå™¨äºº",
                "æŸ¥çœ‹ä»Šæ—¥ä»»åŠ¡ç»Ÿè®¡"
            ],
            metadata={"scenario": "status_query"}
        )

    async def _handle_problem_diagnosis(self, message: str) -> AgentResponse:
        """å¤„ç†é—®é¢˜è¯Šæ–­åœºæ™¯"""

        await asyncio.sleep(0.4)

        reasoning_steps = [
            ReasoningStep(
                step=1,
                action="identify_target",
                description="è¯†åˆ«é—®é¢˜å¯¹è±¡",
                result="æœºå™¨äºº A-03 (28F)",
                duration_ms=42
            ),
            ReasoningStep(
                step=2,
                action="fetch_status",
                description="è·å–æœºå™¨äººçŠ¶æ€",
                result="çŠ¶æ€: å·²æš‚åœ, ç”µé‡: 35%",
                duration_ms=65
            ),
            ReasoningStep(
                step=3,
                action="check_alerts",
                description="æ£€æŸ¥ç›¸å…³å‘Šè­¦",
                result="å‘ç°1æ¡å‘Šè­¦: ç”µé‡ä½",
                duration_ms=58
            ),
            ReasoningStep(
                step=4,
                action="analyze_logs",
                description="åˆ†æè¿è¡Œæ—¥å¿—",
                result="10:25 è§¦å‘ä½ç”µé‡ä¿æŠ¤ï¼Œè‡ªåŠ¨è¿”å›å……ç”µ",
                duration_ms=123
            ),
            ReasoningStep(
                step=5,
                action="diagnose",
                description="ç”Ÿæˆè¯Šæ–­ç»“è®º",
                result="åŸå› : ç”µé‡ä¸è¶³è§¦å‘ä¿æŠ¤æœºåˆ¶",
                duration_ms=45
            ),
            ReasoningStep(
                step=6,
                action="suggest_solution",
                description="æä¾›è§£å†³æ–¹æ¡ˆ",
                result="å»ºè®®: ç­‰å¾…å……ç”µå®Œæˆæˆ–æ‰‹åŠ¨ç¡®è®¤æ¢å¤",
                duration_ms=38
            )
        ]

        return AgentResponse(
            message="""**é—®é¢˜è¯Šæ–­æŠ¥å‘Š**

ğŸ¤– **æœºå™¨äºº:** æ¸…æ´æœºå™¨äºº A-03
ğŸ“ **ä½ç½®:** ç¯çƒè´¸æ˜“å¹¿åœº 5F (å·²è¿”å›å……ç”µç«™)

**é—®é¢˜åŸå› :**
æœºå™¨äººåœ¨æ‰§è¡Œ5Fèµ°å»Šæ¸…æ´ä»»åŠ¡æ—¶ï¼Œç”µé‡é™è‡³20%ä»¥ä¸‹ï¼Œè§¦å‘äº†ä½ç”µé‡ä¿æŠ¤æœºåˆ¶ï¼Œè‡ªåŠ¨æš‚åœä»»åŠ¡å¹¶è¿”å›å……ç”µç«™ã€‚

**æ—¶é—´çº¿:**
- 09:15 - å¼€å§‹5Fèµ°å»Šæ¸…æ´ä»»åŠ¡
- 10:25 - ç”µé‡é™è‡³18%ï¼Œè§¦å‘ä½ç”µé‡å‘Šè­¦
- 10:26 - è‡ªåŠ¨æš‚åœä»»åŠ¡ï¼Œè¿”å›å……ç”µç«™
- 10:32 - åˆ°è¾¾å……ç”µç«™ï¼Œå¼€å§‹å……ç”µ
- å½“å‰ - å……ç”µä¸­ï¼Œç”µé‡35%

**è§£å†³æ–¹æ¡ˆ:**
1. â³ **ç­‰å¾…å……ç”µ** - é¢„è®¡40åˆ†é’Ÿåå……æ»¡ï¼Œè‡ªåŠ¨æ¢å¤å·¥ä½œ
2. ğŸ”„ **ä»»åŠ¡è½¬ç§»** - å°†æœªå®Œæˆä»»åŠ¡åˆ†é…ç»™å…¶ä»–ç©ºé—²æœºå™¨äºº
3. âœ… **æ‰‹åŠ¨æ¢å¤** - ç¡®è®¤ç”µé‡å……è¶³åæ‰‹åŠ¨æ¢å¤ä»»åŠ¡

å»ºè®®é€‰æ‹©æ–¹æ¡ˆ2ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨å°†ä»»åŠ¡åˆ†é…ç»™æœºå™¨äººA-02ã€‚æ˜¯å¦æ‰§è¡Œï¼Ÿ""",
            reasoning_steps=reasoning_steps,
            suggestions=[
                "ç­‰å¾…å……ç”µå®Œæˆ",
                "è½¬ç§»ä»»åŠ¡ç»™å…¶ä»–æœºå™¨äºº",
                "æŸ¥çœ‹æœºå™¨äººè¯¦ç»†çŠ¶æ€"
            ],
            actions=[
                {"type": "transfer_task", "from": "robot_003", "to": "robot_002"}
            ],
            requires_confirmation=True,
            metadata={
                "scenario": "problem_diagnosis",
                "robot_id": "robot_003",
                "issue": "low_battery",
                "recommended_action": "transfer_task"
            }
        )

    async def _handle_data_analysis(self, message: str) -> AgentResponse:
        """å¤„ç†æ•°æ®åˆ†æåœºæ™¯"""

        await asyncio.sleep(0.5)

        reasoning_steps = [
            ReasoningStep(
                step=1,
                action="parse_request",
                description="è§£æåˆ†æéœ€æ±‚",
                result="æ—¶é—´èŒƒå›´: æœ¬å‘¨, æŒ‡æ ‡: æ¸…æ´æ•ˆç‡",
                duration_ms=38
            ),
            ReasoningStep(
                step=2,
                action="fetch_historical",
                description="è·å–å†å²æ•°æ®",
                result="å·²åŠ è½½7å¤©æ•°æ®ï¼Œå…±847æ¡ä»»åŠ¡è®°å½•",
                duration_ms=156
            ),
            ReasoningStep(
                step=3,
                action="calculate_metrics",
                description="è®¡ç®—æ•ˆç‡æŒ‡æ ‡",
                result="å¹³å‡æ•ˆç‡: 125ã¡/å°æ—¶",
                duration_ms=89
            ),
            ReasoningStep(
                step=4,
                action="trend_analysis",
                description="è¶‹åŠ¿åˆ†æ",
                result="æ•ˆç‡æå‡3.2%ï¼Œå‘ˆä¸Šå‡è¶‹åŠ¿",
                duration_ms=112
            ),
            ReasoningStep(
                step=5,
                action="identify_insights",
                description="å‘ç°æ´å¯Ÿ",
                result="å‘ç°3ä¸ªä¼˜åŒ–æœºä¼š",
                duration_ms=78
            ),
            ReasoningStep(
                step=6,
                action="generate_report",
                description="ç”Ÿæˆåˆ†ææŠ¥å‘Š",
                result="æŠ¥å‘Šå·²ç”Ÿæˆ",
                duration_ms=45
            )
        ]

        return AgentResponse(
            message="""**æœ¬å‘¨æ¸…æ´æ•ˆç‡åˆ†ææŠ¥å‘Š**

ğŸ“Š **æ•´ä½“è¡¨ç°: ä¼˜ç§€** â¬†ï¸ +3.2%

**æ ¸å¿ƒæŒ‡æ ‡:**
| æŒ‡æ ‡ | æœ¬å‘¨ | ä¸Šå‘¨ | å˜åŒ– |
|------|------|------|------|
| ä»»åŠ¡å®Œæˆç‡ | 96.8% | 95.2% | â†‘1.6% |
| å¹³å‡æ•ˆç‡ | 125ã¡/h | 121ã¡/h | â†‘3.3% |
| æœºå™¨äººåˆ©ç”¨ç‡ | 87.2% | 85.5% | â†‘1.7% |
| å¼‚å¸¸åœæœºæ¬¡æ•° | 3æ¬¡ | 7æ¬¡ | â†“57% |

**æ¯æ—¥è¶‹åŠ¿:**
```
æ•ˆç‡ (ã¡/å°æ—¶)
130 |           â—
125 |     â—   â—   â—
120 |   â—   â—
115 | â—
    +------------------
      ä¸€ äºŒ ä¸‰ å›› äº” å…­ æ—¥
```

**å…³é”®æ´å¯Ÿ:**
1. ğŸ“ˆ **æ•ˆç‡æŒç»­æå‡** - æœ¬å‘¨æ•ˆç‡è¾ƒä¸Šå‘¨æå‡3.2%ï¼Œä¸»è¦å¾—ç›Šäºè·¯å¾„ä¼˜åŒ–
2. âš¡ **é«˜å³°æ—¶æ®µè¯†åˆ«** - ä¸Šåˆ9-11ç‚¹æ•ˆç‡æœ€é«˜ï¼Œå»ºè®®é›†ä¸­å®‰æ’é‡è¦ä»»åŠ¡
3. ğŸ”‹ **ç”µé‡ç®¡ç†æ”¹å–„** - ä½ç”µé‡å‘Šè­¦å‡å°‘40%ï¼Œå……ç”µè°ƒåº¦æ›´åˆç†

**ä¼˜åŒ–å»ºè®®:**
- å¢åŠ ä¸Šåˆæ—¶æ®µçš„ä»»åŠ¡å¯†åº¦
- è€ƒè™‘åœ¨å¤ªå¤å¹¿åœºå¢åŠ 1å°æœºå™¨äºº
- ä¼˜åŒ–3Fèµ°å»Šçš„æ¸…æ´è·¯å¾„

éœ€è¦æŸ¥çœ‹æ›´è¯¦ç»†çš„åˆ†ææˆ–å¯¼å‡ºæŠ¥è¡¨å—ï¼Ÿ""",
            reasoning_steps=reasoning_steps,
            suggestions=[
                "æŸ¥çœ‹å„æ¥¼å®‡è¯¦ç»†æ•°æ®",
                "å¯¼å‡ºå‘¨æŠ¥PDF",
                "å¯¹æ¯”ä¸Šæœˆæ•°æ®"
            ],
            metadata={
                "scenario": "data_analysis",
                "period": "this_week",
                "efficiency_change": "+3.2%"
            }
        )

    async def _handle_batch_operation(self, message: str) -> AgentResponse:
        """å¤„ç†æ‰¹é‡æ“ä½œåœºæ™¯"""

        await asyncio.sleep(0.35)

        reasoning_steps = [
            ReasoningStep(
                step=1,
                action="parse_condition",
                description="è§£æç­›é€‰æ¡ä»¶",
                result="æ¡ä»¶: ç”µé‡ < 30%",
                duration_ms=42
            ),
            ReasoningStep(
                step=2,
                action="parse_action",
                description="è§£æç›®æ ‡æ“ä½œ",
                result="æ“ä½œ: å¬å›å……ç”µ",
                duration_ms=35
            ),
            ReasoningStep(
                step=3,
                action="query_targets",
                description="æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„æœºå™¨äºº",
                result="æ‰¾åˆ°2å°æœºå™¨äººç¬¦åˆæ¡ä»¶",
                duration_ms=78
            ),
            ReasoningStep(
                step=4,
                action="validate",
                description="éªŒè¯æ“ä½œå¯è¡Œæ€§",
                result="2å°æœºå™¨äººå¯å®‰å…¨å¬å›",
                duration_ms=56
            ),
            ReasoningStep(
                step=5,
                action="impact_analysis",
                description="åˆ†ææ“ä½œå½±å“",
                result="å½±å“: 2ä¸ªè¿›è¡Œä¸­ä»»åŠ¡å°†æš‚åœ",
                duration_ms=89
            ),
            ReasoningStep(
                step=6,
                action="generate_plan",
                description="ç”Ÿæˆæ‰§è¡Œè®¡åˆ’",
                result="å·²ç”Ÿæˆæ‰¹é‡å¬å›è®¡åˆ’",
                duration_ms=45
            )
        ]

        return AgentResponse(
            message="""**æ‰¹é‡æ“ä½œç¡®è®¤**

ğŸ” **ç­›é€‰æ¡ä»¶:** ç”µé‡ä½äº30%çš„æœºå™¨äºº
âš¡ **ç›®æ ‡æ“ä½œ:** å¬å›è‡³å……ç”µç«™

**ç¬¦åˆæ¡ä»¶çš„æœºå™¨äºº:**
| æœºå™¨äºº | å½“å‰ç”µé‡ | ä½ç½® | å½“å‰ä»»åŠ¡ |
|--------|----------|------|----------|
| A-03 | 25% | ç¯çƒè´¸æ˜“å¹¿åœº 5F | èµ°å»Šæ¸…æ´ (è¿›åº¦68%) |
| B-02 | 28% | å›½é™…é‡‘èä¸­å¿ƒ 4F | åŠå…¬åŒºæ¸…æ´ (è¿›åº¦45%) |

**æ“ä½œå½±å“:**
- â¸ï¸ 2ä¸ªè¿›è¡Œä¸­çš„ä»»åŠ¡å°†è¢«æš‚åœ
- ğŸ“‹ æš‚åœçš„ä»»åŠ¡å°†è‡ªåŠ¨åŠ å…¥å¾…å¤„ç†é˜Ÿåˆ—
- â±ï¸ é¢„è®¡å½±å“æ¸…æ´è¿›åº¦çº¦30åˆ†é’Ÿ

**å»ºè®®å¤„ç†æ–¹æ¡ˆ:**
1. ç«‹å³å¬å› - ä»»åŠ¡è‡ªåŠ¨è½¬ç§»ç»™å…¶ä»–æœºå™¨äºº
2. å®Œæˆå½“å‰ä»»åŠ¡åå¬å› - å»¶è¿Ÿçº¦20åˆ†é’Ÿ
3. ä»…å¬å›A-03 - B-02ç”µé‡å¯æ”¯æ’‘å®Œæˆå½“å‰ä»»åŠ¡

ç¡®è®¤æ‰§è¡Œæ‰¹é‡å¬å›æ“ä½œï¼Ÿ""",
            reasoning_steps=reasoning_steps,
            suggestions=[
                "ç«‹å³æ‰§è¡Œå¬å›",
                "å®Œæˆä»»åŠ¡åå¬å›",
                "ä»…å¬å›ç”µé‡æœ€ä½çš„æœºå™¨äºº"
            ],
            actions=[
                {"type": "recall", "robot_id": "robot_003"},
                {"type": "recall", "robot_id": "robot_005"}
            ],
            requires_confirmation=True,
            metadata={
                "scenario": "batch_operation",
                "operation": "recall",
                "target_count": 2,
                "affected_tasks": 2
            }
        )

    def _generate_fallback_response(self) -> AgentResponse:
        """ç”Ÿæˆé»˜è®¤å“åº”"""
        return AgentResponse(
            message="""æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å®Œå…¨ç†è§£æ‚¨çš„éœ€æ±‚ã€‚æ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹æ“ä½œ:

- **ä»»åŠ¡è°ƒåº¦:** "å®‰æ’æ˜å¤©æ—©ä¸Šå¤§å ‚æ·±åº¦æ¸…æ´"
- **çŠ¶æ€æŸ¥è¯¢:** "ç°åœ¨æœ‰å“ªäº›æœºå™¨äººç©ºé—²"
- **é—®é¢˜è¯Šæ–­:** "28æ¥¼çš„æœºå™¨äººæ€ä¹ˆåœäº†"
- **æ•°æ®åˆ†æ:** "è¿™å‘¨çš„æ¸…æ´æ•ˆç‡æ€ä¹ˆæ ·"
- **æ‰¹é‡æ“ä½œ:** "æŠŠæ‰€æœ‰ç”µé‡ä½äº30%çš„æœºå™¨äººå¬å›å……ç”µ"

è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³åšä»€ä¹ˆï¼Ÿ""",
            reasoning_steps=[
                ReasoningStep(
                    step=1,
                    action="fallback",
                    description="æœªèƒ½è¯†åˆ«ç”¨æˆ·æ„å›¾",
                    result="æä¾›å¸®åŠ©é€‰é¡¹",
                    duration_ms=15
                )
            ],
            suggestions=[
                "æŸ¥çœ‹æœºå™¨äººçŠ¶æ€",
                "å®‰æ’æ¸…æ´ä»»åŠ¡",
                "æŸ¥çœ‹ä»Šæ—¥æ•°æ®"
            ]
        )

    # ==================== ç¡®è®¤å’Œå­¦ä¹  ====================

    async def confirm_action(self, session_id: str, confirmed: bool, feedback: Optional[str] = None) -> Dict[str, Any]:
        """ç¡®è®¤æˆ–æ‹’ç»Agentå»ºè®®çš„æ“ä½œ"""

        result = {
            "confirmed": confirmed,
            "session_id": session_id,
            "timestamp": datetime.now().isoformat()
        }

        if confirmed:
            result["message"] = "æ“ä½œå·²ç¡®è®¤æ‰§è¡Œ"
            result["status"] = "executed"
        else:
            result["message"] = "æ“ä½œå·²å–æ¶ˆ"
            result["status"] = "cancelled"

            # å¦‚æœæœ‰åé¦ˆï¼Œè®°å½•å­¦ä¹ 
            if feedback:
                await self.record_learning(session_id, feedback)
                result["learning_recorded"] = True

        # è®°å½•åˆ°å¯¹è¯
        if session_id in self._conversations:
            self._conversations[session_id].append(
                ConversationMessage(
                    role="system",
                    content=f"ç”¨æˆ·{'ç¡®è®¤' if confirmed else 'å–æ¶ˆ'}äº†æ“ä½œ" + (f"ï¼Œåé¦ˆ: {feedback}" if feedback else "")
                )
            )

        return result

    async def record_learning(self, session_id: str, feedback: str) -> Dict[str, Any]:
        """è®°å½•å­¦ä¹ åé¦ˆ"""

        learning_record = {
            "id": f"learn_{len(self._learning_records) + 1:04d}",
            "session_id": session_id,
            "feedback": feedback,
            "timestamp": datetime.now().isoformat(),
            "applied": False
        }

        self._learning_records.append(learning_record)

        logger.info(f"Learning recorded: {feedback}")

        return {
            "success": True,
            "learning_id": learning_record["id"],
            "message": f"å·²è®°å½•æ‚¨çš„åé¦ˆ: {feedback}\nä¸‹æ¬¡æˆ‘ä¼šè€ƒè™‘è¿™ä¸ªå› ç´ åšå‡ºæ›´å¥½çš„å†³ç­–ã€‚"
        }

    # ==================== é¢„è®¾åœºæ™¯æ¼”ç¤º ====================

    def get_preset_scenarios(self) -> List[Dict[str, Any]]:
        """è·å–é¢„è®¾åœºæ™¯åˆ—è¡¨"""
        return [
            {
                "id": scenario.value,
                "name": config["name"],
                "description": config["description"],
                "sample_inputs": config["sample_inputs"]
            }
            for scenario, config in self._scenario_configs.items()
        ]

    async def run_demo_conversation(self, scenario: ConversationScenario) -> Dict[str, Any]:
        """è¿è¡Œé¢„è®¾æ¼”ç¤ºå¯¹è¯"""

        session_id = f"demo_{scenario.value}_{datetime.now().strftime('%H%M%S')}"
        config = self._scenario_configs.get(scenario, {})

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªç¤ºä¾‹è¾“å…¥
        sample_input = config.get("sample_inputs", ["ä½ å¥½"])[0]

        # å¤„ç†æ¶ˆæ¯
        response = await self.process_message(session_id, sample_input, scenario)

        return {
            "session_id": session_id,
            "scenario": scenario.value,
            "scenario_name": config.get("name", "æœªçŸ¥"),
            "user_input": sample_input,
            "response": response.to_dict(),
            "conversation": [msg.to_dict() for msg in self._conversations.get(session_id, [])]
        }

    # ==================== ä¼šè¯ç®¡ç† ====================

    def get_conversation(self, session_id: str) -> List[Dict[str, Any]]:
        """è·å–ä¼šè¯å†å²"""
        return [msg.to_dict() for msg in self._conversations.get(session_id, [])]

    def clear_conversation(self, session_id: str) -> bool:
        """æ¸…é™¤ä¼šè¯"""
        if session_id in self._conversations:
            del self._conversations[session_id]
            return True
        return False

    def get_learning_records(self) -> List[Dict[str, Any]]:
        """è·å–å­¦ä¹ è®°å½•"""
        return self._learning_records


# å…¨å±€å®ä¾‹
agent_conversation_service = AgentConversationService()
